# Emotion-Detection-from-speech
This project detects human emotions from speech using MFCC feature extraction and a Random Forest Classifier. It can identify emotions such as happy, sad, angry, calm, fearful, and neutral. A Streamlit web app is included for real-time emotion detection through microphone input, making the system easy to use andÂ interactive.

# Emotion Detection from Speech ğŸ¤  

This project focuses on detecting **human emotions from speech** using **Machine Learning techniques**. By analyzing audio features such as **MFCC (Mel-Frequency Cepstral Coefficients)**, the system classifies emotions into categories like **Happy, Sad, Angry, Calm, Fearful, and Neutral**.  
It also provides a **Streamlit Web Application** that allows real-time predictions through microphone input, making the system both interactive and practical.  

---

## ğŸ“‚ Project Structure  

Emotion-Detection-from-Speech/
â”‚â”€â”€ app.py # Streamlit Web Application
â”‚â”€â”€ train_model.py # Script to train the model
â”‚â”€â”€ sample.py # Script to test audio files
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ models/
â”‚ â””â”€â”€ emotion_model.pkl # Trained Model File
â”‚â”€â”€ results.png # Results Image
â”‚â”€â”€

---

## ğŸ“Œ Features  
- Detects emotions from speech audio  
- Real-time microphone input support  
- Uses **MFCC feature extraction**  
- Built with **Random Forest Classifier**  
- Web interface created using **Streamlit**  
- Provides instant predictions with a pre-trained model  

--- 

â–¶ï¸ Usage
Run the Web Application
streamlit run app.py
- Click Record and Analyze

- Speak for a few seconds into your microphone

- The predicted emotion will be displayed on the screen

| Audio File               | Predicted Emotion |
| ------------------------ | ----------------- |
| 03-02-03-01-02-02-24.wav | Happy ğŸ˜Š          |
| 03-02-04-01-01-02-23.wav | Sad ğŸ˜”            |
| 03-02-05-02-01-01-24.wav | Angry ğŸ˜¡          |
| 03-02-06-02-02-01-23.wav | Fearful ğŸ˜¨ 
    
___

ğŸ“Š Confusion Matrix Results

The confusion matrix above illustrates the performance of the Speech Emotion Detection model across six emotions: angry, calm, fearful, happy, neutral, and sad. Each row represents the actual emotion, while each column represents the predicted emotion.

âœ… The diagonal values indicate correct predictions.

âŒ Off-diagonal values show where the model confused one emotion with another.

The model achieved high accuracy for emotions like sad (34 correct) and angry (33 correct).

Some misclassifications occurred, such as fearful being confused with angry and happy with fearful.

---

 ğŸ“Š Results
Sample Results

ğŸ§ 03-02-03-01-02-02-24.wav â†’ Happy ğŸ˜Š

ğŸ§ 03-02-04-01-01-02-23.wav â†’ Sad ğŸ˜”

ğŸ§ 03-02-05-02-01-01-24.wav â†’ Angry ğŸ˜¡

ğŸ§ 03-02-06-02-02-01-23.wav â†’ Fearful ğŸ˜¨

ğŸ§ 03-02-01-01-02-02-23.wav â†’ Neutral ğŸ˜

ğŸ§ 03-02-02-01-02-01-24.wav â†’ Calm ğŸ˜Œ


---

ğŸ¤ Contributing
Contributions are always welcome.
To contribute:

- Fork the repository

- Create a new feature branch

- Commit your changes

- Push to your branch

- Open a Pull Request

---

ğŸ“œ License
This project is licensed under the MIT License.



