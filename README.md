# Emotion Detection from Speech ğŸ¤  

This project focuses on detecting **human emotions from speech** using **Machine Learning techniques**. By analyzing audio features such as **MFCC (Mel-Frequency Cepstral Coefficients)**, the system classifies emotions into categories like **Happy, Sad, Angry, Calm, Fearful, and Neutral**.  
It also provides a **Streamlit Web Application** that allows real-time predictions through microphone input, making the system both interactive and practical.  

---

## ğŸ“‚ Project Structure  

Emotion-Detection-from-Speech/
â”‚â”€â”€ app.py # Streamlit Web Application
â”‚â”€â”€ train_model.py # Script to train the model
â”‚â”€â”€ sample.py # Script to test audio files
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ models/
â”‚ â””â”€â”€ emotion_model.pkl # Trained Model File
â”‚â”€â”€ results.png # Results Image
â”‚â”€â”€

---

## ğŸ“Œ Features  
- Detects emotions from speech audio  
- Real-time microphone input support  
- Uses **MFCC feature extraction**  
- Built with **Random Forest Classifier**  
- Web interface created using **Streamlit**  
- Provides instant predictions with a pre-trained model  

--- 

â–¶ï¸ Usage
Run the Web Application
streamlit run app.py
- Click Record and Analyze

- Speak for a few seconds into your microphone

- The predicted emotion will be displayed on the screen

| Audio File               | Predicted Emotion |
| ------------------------ | ----------------- |
| 03-02-03-01-02-02-24.wav | Happy ğŸ˜Š          |
| 03-02-04-01-01-02-23.wav | Sad ğŸ˜”            |
| 03-02-05-02-01-01-24.wav | Angry ğŸ˜¡          |
| 03-02-06-02-02-01-23.wav | Fearful ğŸ˜¨ 
    
___

ğŸ“Š Confusion Matrix Results

<img width="1366" height="655" alt="Figure_1" src="https://github.com/user-attachments/assets/1545a430-eab2-4ca7-a6f5-295c2f558e10" />


The confusion matrix above illustrates the performance of the Speech Emotion Detection model across six emotions: angry, calm, fearful, happy, neutral, and sad. Each row represents the actual emotion, while each column represents the predicted emotion.

âœ… The diagonal values indicate correct predictions.

âŒ Off-diagonal values show where the model confused one emotion with another.

The model achieved high accuracy for emotions like sad (34 correct) and angry (33 correct).

Some misclassifications occurred, such as fearful being confused with angry and happy with fearful.

---

 ğŸ“Š Results
Sample Results

ğŸ§ 03-02-03-01-02-02-24.wav â†’ Happy ğŸ˜Š

ğŸ§ 03-02-04-01-01-02-23.wav â†’ Sad ğŸ˜”

ğŸ§ 03-02-05-02-01-01-24.wav â†’ Angry ğŸ˜¡

ğŸ§ 03-02-06-02-02-01-23.wav â†’ Fearful ğŸ˜¨

ğŸ§ 03-02-01-01-02-02-23.wav â†’ Neutral ğŸ˜

ğŸ§ 03-02-02-01-02-01-24.wav â†’ Calm ğŸ˜Œ

<img width="1245" height="653" alt="Screenshot 2025-08-03 172158" src="https://github.com/user-attachments/assets/69109918-9ef5-414b-bd5d-a278763f75c0" />
- After recorded
<img width="1208" height="657" alt="Screenshot 2025-08-03 172633" src="https://github.com/user-attachments/assets/d74d0b6b-21db-4673-9edc-ad697ca060d6" />

---

ğŸŒ Streamlit Web Application

This project includes a Streamlit web application that allows real-time emotion detection from speech. Through the app, users can record their voice using a microphone, and the system immediately analyzes the audio to predict the corresponding emotion. This makes the model more interactive and user-friendly, providing quick results without runningÂ codeÂ manually.

Results:
- Audio File
<img width="1320" height="665" alt="Screenshot 2025-08-03 173418" src="https://github.com/user-attachments/assets/6cf48910-8d6f-45f5-97b8-e07430a3e751" />

- Record file
<img width="1355" height="666" alt="Screenshot 2025-08-03 173540" src="https://github.com/user-attachments/assets/7a6dcc87-3c88-4983-969e-c8e349c70887" />

---

ğŸ“œ License
This project is licensed under the MIT License.

---



